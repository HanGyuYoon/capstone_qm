{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기에 넣어 줄 랜덤 넘버\n",
    "batch_size = 1000\n",
    "input_scale = 10\n",
    "bins = 201\n",
    "iteration = 1000000\n",
    "cost_graph=[]\n",
    "iteration_graph=[]\n",
    "input = tf.random_normal([batch_size,input_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test용 input, potential\n",
    "potential = tf.constant(0.0, shape = [batch_size,bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#웨이트, 바이어스\n",
    "'''간단하게 기존의 프로그램과 차이점은 기존의 프로그램에 두번째 스테이트를 쌓는 다는 점이다.'''\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "# weight = tf.zeros([2, input_scale, bins], dtype = tf.float32)\n",
    "# weight = tf.zeros([input_scale, bins], dtype = tf.float32)\n",
    "weight1 = tf.Variable(initializer([input_scale, bins]), dtype = tf.float32)\n",
    "bias1 = tf.Variable(initializer([bins]), dtype = tf.float32)\n",
    "weight2 = tf.Variable(initializer([input_scale, bins]), dtype = tf.float32)\n",
    "bias2 = tf.Variable(initializer([bins]), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_loss, b1_loss, w2_loss, b2_loss = tf.nn.l2_loss(weight1), tf.nn.l2_loss(bias1), tf.nn.l2_loss(weight2), tf.nn.l2_loss(bias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-e94e73f62dcb>:10: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "binsnorm = tf.sqrt(tf.cast(bins, tf.float32))\n",
    "#프사이 1\n",
    "psi_1 = tf.matmul(input, weight1) + bias1\n",
    "psi_1 = tf.divide(psi_1,tf.sqrt(tf.reduce_mean(tf.square(psi_1), axis = 1, keepdims = True)))/binsnorm\n",
    "\n",
    "## 에너지 1\n",
    "zeroten = tf.zeros([batch_size, 1], tf.float32)\n",
    "psil_1 = tf.concat([psi_1[:,1:],zeroten],1)\n",
    "psir_1 = tf.concat([zeroten,psi_1[:,:-1]],1)\n",
    "energy_1 = tf.reduce_mean(tf.subtract(tf.multiply(tf.square(psi_1*binsnorm),tf.add(potential,1.*bins*bins)),tf.multiply(tf.multiply(tf.add(psil_1*binsnorm,psir_1*binsnorm),psi_1*binsnorm),0.5*bins*bins)), axis=-1, keep_dims=True)\n",
    "\n",
    "## 그람슈미츠 직교화\n",
    "'''그람슈미츠 직교화를 통해 프사이1과 orthonormal한 프사이2를 만드는 과정이다.'''\n",
    "psi_2 = tf.matmul(input, weight2) + bias2\n",
    "dotprod_1_2 = tf.multiply(tf.reduce_sum(tf.multiply(psi_1, psi_2), axis = 1, keepdims = True), psi_1)\n",
    "psi_2 = psi_2-dotprod_1_2\n",
    "psi_2 = tf.divide(psi_2,tf.sqrt(tf.reduce_mean(tf.square(psi_2), axis = 1, keepdims = True)))/binsnorm\n",
    "\n",
    "\n",
    "psil_2 = tf.concat([psi_2[:,1:],zeroten],1)\n",
    "psir_2 = tf.concat([zeroten,psi_2[:,:-1]],1)\n",
    "energy_2 = tf.reduce_mean(tf.subtract(tf.multiply(tf.square(psi_2*binsnorm),tf.add(potential,1.*bins*bins)),tf.multiply(tf.multiply(tf.add(psil_2*binsnorm,psir_2*binsnorm),psi_2*binsnorm),0.5*bins*bins)), axis=-1, keep_dims=True)\n",
    "\n",
    "## Leanier combination\n",
    "'''사실 이 계수는 별로 중요하지 않다. 왜냐하면 두 파동함수가 직교하기 때문에\n",
    "첫번째 프사이가 그라운드 스테이트로 간 후,\n",
    "두번째 프사이가 그라운드 스테이트로 가기 위해서 무조건 첫번째 들뜬 상태로 간다'''\n",
    "C=1/tf.sqrt(2.)\n",
    "C_1 = C*tf.ones(shape=[batch_size, 1])\n",
    "C_2 = C*tf.ones(shape=[batch_size, 1])\n",
    "psi = tf.add(tf.multiply(C_1, psi_1), tf.multiply(C_2, psi_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy = (C_1**2)*energy_1+(C_2**2)*energy_2\n",
    "# total_energy = energy_1\n",
    "# cost = tf.reduce_mean(total_energy)\n",
    "cost = tf.reduce_mean(total_energy)+0.02*(w1_loss+w2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''여기선 varlist라는 개념을 사용했는데 이는 텐서플로가 변수로 인식하는 부분을 의미한다.\n",
    "첫번째 학습에서는 웨이트1과 바이어스1만이 텐서플로의 변수이고\n",
    "두번째 학습에서는 웨이트2와 바이어스2만이 변수로 작용한다.'''\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(energy_1, var_list=[weight1, bias1])\n",
    "train2 = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost, var_list=[weight2, bias2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''생각보다 프로그램이 무거워져서 GPU를 사용해야 빠르게 돌아간다.'''\n",
    "# If you want to use CPU\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# If you want to use GPU\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''기존으 프로그램을 통해 이터레이션이 약 20000정도 진행되면 충분히 그라운드 스테이트에 도달한다는 점을\n",
    "착안하여, 30000번 쯤을 기준으로 학습1에서 학습2로 넘어가게 설정했다.\n",
    "파란색은 그라운드, 초록색은 퍼스트, 빨간색은 이 둘의 합을 나타내는데\n",
    "퍼스트가 한쪽으로 치우친 두가지형태가 있기 때문에 둘의 합도 한쪽으로 치우치게 된다.\n",
    "그림에서 퍼스트가 대칭인 이유는 제곱이기 때문.'''\n",
    "for i in range (iteration):  \n",
    "    if i <30000:\n",
    "        sess.run(train)\n",
    "    else :\n",
    "        sess.run(train2)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        psi_total,psi_1v,psi_2v,cost_now,w1_loss_v,b1_loss_v,w2_loss_v,b2_loss_v, energy1_now, energy2_now = sess.run([psi, psi_1, psi_2, cost, w1_loss, b1_loss, w2_loss, b2_loss, tf.reduce_mean(energy_1), tf.reduce_mean(energy_2)])\n",
    "        prob_total,prob_1v,prob_2v = psi_total**2, psi_1v**2, psi_2v**2  \n",
    "        print(\"iteration=%d, cost=%f, energy1=%f, energy2=%f\" % (i, cost_now, energy1_now, energy2_now))\n",
    "        print(\"W1_loss=%f, B1_loss=%f, W2_loss=%f, B2_loss=%f\" % (w1_loss_v, b1_loss_v, w2_loss_v, b2_loss_v))\n",
    "        if i < 30000:\n",
    "            plt.plot(prob_1v[0], '-b')\n",
    "        else:\n",
    "            plt.plot(prob_1v[0], '-b')\n",
    "            plt.plot(prob_total[0], '-r')\n",
    "            plt.plot(prob_2v[0], '-g')\n",
    "        plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
